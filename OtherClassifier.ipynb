{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iannashon/cse6250/blob/main/OtherClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KV-0i3UYdYz"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT1CCvnehz4E"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow_decision_forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BCqp7E3YIJq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_decision_forests as tfdf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZbNnPUOYmsX"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"drive/MyDrive/mimicdb/dataset_05.csv\")\n",
        "# dataset.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CwU7LcTxYKB",
        "outputId": "0c7ba491-9208-491c-b1ba-ee2f817abfc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isReadmission  isEarlyReadmission\n",
              "False          False                 10436\n",
              "True           False                  2646\n",
              "               True                    958\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset.groupby(['isReadmission','isEarlyReadmission']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2Op0a3pLGT0"
      },
      "outputs": [],
      "source": [
        "# dataset.head()\n",
        "def check_imbalance(dataset):\n",
        "  xx = dataset[\"isReadmission\"].value_counts().reset_index()\n",
        "  sns.barplot(x=\"index\", y=\"isReadmission\", data=xx, palette=\"cividis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBeY0X4iNqZQ"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(dataset[\"TEXT\"], dataset[\"TEXT_LN\"], test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbcGXoifbg40"
      },
      "outputs": [],
      "source": [
        "def remove_numbers_and_special_character(text):\n",
        "    text_cln = re.sub('[^A-Za-z]+', ' ', str(text))\n",
        "    return text_cln\n",
        "  \n",
        "\n",
        "def clean_text(text ): \n",
        "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
        "    delete_dict[' '] = ' ' \n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table)\n",
        "    textArr= text1.split()\n",
        "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n",
        "    \n",
        "    return text2.lower()\n",
        "\n",
        "\n",
        "def split_dataset(train_data):\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(train_data['TEXT'].tolist(),\\\n",
        "                                                      train_data['isEarlyReadmission'].tolist(),\\\n",
        "                                                      test_size=0.3,\\\n",
        "                                                      random_state=42)\n",
        "  return X_train, X_valid, y_train, y_valid\n",
        "\n",
        "def label_tx(y_train):\n",
        "  le = LabelEncoder()\n",
        "  train_labels = le.fit_transform(y_train)\n",
        "  # train_labels = np.asarray( tf.keras.utils.to_categorical(train_labels))\n",
        "  return train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsIMoQ2HbtaS",
        "outputId": "cb43c2fa-1d07-4cf0-f708-76f90d4d3e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14040\n"
          ]
        }
      ],
      "source": [
        "dataset['TEXT'] = dataset['TEXT'].apply(remove_numbers_and_special_character)\n",
        "dataset['TEXT'] = dataset['TEXT'].apply(clean_text)\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg4ZsJFibwyI"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_dataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAUZuVE6yA7Z",
        "outputId": "1b72c2c0-f1c5-47b0-e465-6fd6cd2719c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4212\n"
          ]
        }
      ],
      "source": [
        "print(len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFD2B4rrcRVx"
      },
      "outputs": [],
      "source": [
        "ytrain= label_tx(y_train)\n",
        "ytest= label_tx(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5ylLK9TyXQN",
        "outputId": "4e801608-0fbd-4aa4-e956-f60e24cbfee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "[3934  278]\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(ytest, return_counts=True)\n",
        "print(unique)\n",
        "print(counts)\n",
        "# print(type(ytrain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H4S5n7RIUdj"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer() \n",
        "tfidf_train_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
        "tfidf_test_vectors = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kemSWp7v3uf_",
        "outputId": "3e2b7d89-527a-49b3-d51d-3b26f7d60dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "idf = tfidf_vectorizer.idf_\n",
        "# print(idf.shape)\n",
        "word_vec_model = dict(zip(tfidf_vectorizer.get_feature_names(), idf))\n",
        "# print(word_vec_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5M-eyim7fOU",
        "outputId": "bb24db31-7add-45f2-ae32-a836535ca2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-451ba355e765>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(features)\n"
          ]
        }
      ],
      "source": [
        "def word_embedding(train, model):\n",
        "  features = []\n",
        "  for data in train:\n",
        "    # print(data)\n",
        "    text_splt = data.split()\n",
        "    txt_arry = []\n",
        "    for text in text_splt:\n",
        "      weight = model.get(text)\n",
        "      # weight_arry = []\n",
        "      if weight is not None:\n",
        "        # weight_arry.append(weight)\n",
        "        txt_arry.append(weight)\n",
        "    \n",
        "    txt_arry_np = np.asarray(txt_arry).astype(np.float32)\n",
        "    features.append(txt_arry_np)\n",
        "\n",
        "  return np.array(features)\n",
        "\n",
        "def x_padding(train):\n",
        "  inputs = pad_sequences(train, padding='post', maxlen=1000, dtype='float32')\n",
        "  # inputs = inputs.astype(np.float32)\n",
        "  return inputs\n",
        "\n",
        "# print(X_train[0])\n",
        "X_train = word_embedding(X_train, word_vec_model)\n",
        "X_train = x_padding(X_train)\n",
        "\n",
        "X_test = word_embedding(X_test, word_vec_model)\n",
        "X_test = x_padding(X_test)\n",
        "\n",
        "# print(xtrain[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxNhJryzhavy",
        "outputId": "cf64f4fb-44d5-47c7-dbd5-10a6788f7b70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train,ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjDOgLlXOamI"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RknW333Odo1",
        "outputId": "0152b4a7-d16a-4903-c523-0336b6cc0fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      1.00      0.97      3934\n",
            "        True       0.00      0.00      0.00       278\n",
            "\n",
            "    accuracy                           0.93      4212\n",
            "   macro avg       0.47      0.50      0.48      4212\n",
            "weighted avg       0.87      0.93      0.90      4212\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xcR4mRKjexv"
      },
      "outputs": [],
      "source": [
        "model = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(X_train,ytrain)\n",
        "\n",
        "#Predict Output\n",
        "predicted= model.predict(X_test) # 0:Overcast, 2:Mild\n",
        "# print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkK9MJBaQ_VF",
        "outputId": "60ec2254-b6be-4a4f-f85c-9f13181e38ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.99      0.96      3934\n",
            "        True       0.15      0.02      0.04       278\n",
            "\n",
            "    accuracy                           0.93      4212\n",
            "   macro avg       0.54      0.51      0.50      4212\n",
            "weighted avg       0.88      0.93      0.90      4212\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,predicted))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "from numpy import *\n",
        "\n",
        "random.seed(1234)\n",
        "clf = svm.SVC(kernel='rbf') \n",
        "clf.fit(X_train, ytrain)\n",
        "ys_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "GtZzAvGaTobG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,ys_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH-fGi5fT2Zj",
        "outputId": "eab39ddd-f7fe-4501-b2ab-edfe6a1318ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      1.00      0.97      3934\n",
            "        True       0.00      0.00      0.00       278\n",
            "\n",
            "    accuracy                           0.93      4212\n",
            "   macro avg       0.47      0.50      0.48      4212\n",
            "weighted avg       0.87      0.93      0.90      4212\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1MgAqkXUboT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8Gl7Ku8r/s11nTrv5GqAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}